{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Language Modeling using Ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will write a code using NLTK which is a natural language processing library for python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import necessary library such as math, nltk, bigram, and collections. We also already download 'gutenberg' corpus from nltk to use as input data for our language modeling task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'austen-emma.txt',\n",
       " u'austen-persuasion.txt',\n",
       " u'austen-sense.txt',\n",
       " u'bible-kjv.txt',\n",
       " u'blake-poems.txt',\n",
       " u'bryant-stories.txt',\n",
       " u'burgess-busterbrown.txt',\n",
       " u'carroll-alice.txt',\n",
       " u'chesterton-ball.txt',\n",
       " u'chesterton-brown.txt',\n",
       " u'chesterton-thursday.txt',\n",
       " u'edgeworth-parents.txt',\n",
       " u'melville-moby_dick.txt',\n",
       " u'milton-paradise.txt',\n",
       " u'shakespeare-caesar.txt',\n",
       " u'shakespeare-hamlet.txt',\n",
       " u'shakespeare-macbeth.txt',\n",
       " u'whitman-leaves.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project gutenberg is a public collaboration to provide free e-book to the internet. \n",
    "The list of project gutenberg's available books in nltk is as listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sentences in Moby Dick :\t10059\n",
      "total word counts in Moby Dick :\t260819\n",
      "total vocabuary in Moby Dick :\t19317\n"
     ]
    }
   ],
   "source": [
    "print 'total sentences in Moby Dick :\\t'+ str(len(nltk.corpus.gutenberg.sents('melville-moby_dick.txt')))\n",
    "print 'total word counts in Moby Dick :\\t'+ str(len(nltk.corpus.gutenberg.words('melville-moby_dick.txt')))\n",
    "print 'total vocabuary in Moby Dick :\\t'+ str(len(set(nltk.corpus.gutenberg.words('melville-moby_dick.txt'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence example:\n",
      "[u'He', u'loved', u'to', u'dust', u'his', u'old', u'grammars', u';', u'it', u'somehow', u'mildly', u'reminded', u'him', u'of', u'his', u'mortality', u'.']\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.corpus.gutenberg.sents('melville-moby_dick.txt')\n",
    "print 'sentence example:'\n",
    "print sentences[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = sentences[:9000]\n",
    "test = sentences[9000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate out input into 2 sets, input and test data. Input data is consisted of the first 9000 sentences in the book. Test data is consisted of 1059 last sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for sentence in train:\n",
    "    for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True): #None I go to school . None\n",
    "        model[w1][w2] +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we created our simple language model using only bigrams. The left and right padding are for the before and after marker which use None as a token. We counted the occurrences of a couple of words in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w1 in model:\n",
    "    unigram = float(sum(model[w1].values()))\n",
    "    for w2 in model[w1]:\n",
    "        #model[w1][w2] = model[w1][w2]/total_count\n",
    "        model[w1][w2] = math.log(model[w1][w2]/unigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bigram problability is calculated by this formula log(P(w2,w1)) = log(Count(w2,w1)/Count(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(P(\"man\", \"old\")) :-1.76314893519\n"
     ]
    }
   ],
   "source": [
    "print 'log(P(\"man\", \"old\")) :'+ str(model['old']['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_sentence_ln_prob(sentence):\n",
    "    if type(sentence) is str:\n",
    "        sent =sentence.split(' ')\n",
    "    else:\n",
    "        sent = sentence\n",
    "    prob =.0\n",
    "    for i in range(0,len(sent)-1):\n",
    "        if i==0:\n",
    "            prob+=model[None][sent[i]]\n",
    "        elif i==len(sent)-2:\n",
    "            prob+=model[sent[i+1]][None]\n",
    "        prob +=model[sent[i]][sent[i+1]]\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.1992792398\n",
      "-33.9052909877\n"
     ]
    }
   ],
   "source": [
    "print calculate_sentence_prob('The old man is swimming in the sea .')\n",
    "print calculate_sentence_prob('The old man and swimming in the sea .')\n",
    "#print model[None]['The']+model['The']['old']+model['old']['man']+model['man'][None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is for calculating the problability of a sentence. However the sentence usually lack the start and stop marker so we need to add it ourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perplexity(test):\n",
    "    prob=.0\n",
    "    words=0\n",
    "    for sent in test:\n",
    "        words+=len(sent)\n",
    "        prob += calculate_sentence_prob(sent)\n",
    "    #return math.pow(prob,-words)\n",
    "    return math.exp(-prob/words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5136522426\n"
     ]
    }
   ],
   "source": [
    "print perplexity(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is for perplexity calculation, which after taking logarithm of e, can be expressed as \n",
    "\n",
    "PERPLEXITY = e^((-1/word_count)*(Sum of all sentences problability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101.708519808\n"
     ]
    }
   ],
   "source": [
    "#Laplace Smoothing\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for sentence in train:\n",
    "    for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):\n",
    "        model[w1][w2] +=1\n",
    "v = len(set(nltk.corpus.gutenberg.words('melville-moby_dick.txt')))\n",
    "for w1 in model:\n",
    "    unigram_count = float(sum(model[w1].values()))\n",
    "    for w2 in model[w1]:\n",
    "        model[w1][w2] = math.log((model[w1][w2]+1)/(unigram_count+v))\n",
    "        #model[w1][w2]/=total_count\n",
    "print perplexity(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.9617761056\n"
     ]
    }
   ],
   "source": [
    "#interpolation\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for sentence in train:\n",
    "    for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):\n",
    "        model[w1][w2] +=1\n",
    "total = len(nltk.corpus.gutenberg.words('melville-moby_dick.txt'))\n",
    "for w1 in model:\n",
    "    unigram_count = float(sum(model[w1].values()))\n",
    "    for w2 in model[w1]:\n",
    "        model[w1][w2] = math.log(((0.7*model[w1][w2])/(unigram_count))+(0.3*unigram_count/total))\n",
    "        #model[w1][w2]/=total_count\n",
    "print perplexity(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram interpolation is consisted of P(w2,w1) + P(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cruppered with mild looking sky .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    " \n",
    "text = [None]\n",
    "sentence_finished = False\n",
    " \n",
    "while not sentence_finished:\n",
    "    r = random.random()\n",
    "    accumulator = .0\n",
    " \n",
    "    for word in model[text[-1:][0]].keys():\n",
    "        accumulator += math.exp(model[text[-1:][0]][word])\n",
    "        if accumulator >= r:\n",
    "            text.append(word)\n",
    "            break\n",
    " \n",
    "    if text[-1:] == [None]:\n",
    "        sentence_finished = True\n",
    "print ' '.join([t for t in text if t])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
